{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5258058e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd7f212-e02d-46e3-9235-f24bce2fcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pylab\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import skimage.io as imageio\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "#from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.layers import Concatenate, Input, concatenate, add, multiply, maximum\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#K.set_image_dim_ordering('th')\n",
    "K.set_image_data_format('channels_first')\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ca99e",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4776d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afb8ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f82c1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70eb322-89a3-483b-9939-5af8d835af45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1321c0-b8a5-4531-a3fa-53984aad7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLib Face Detection\n",
    "predictor_path = \"/Thesis/MicroExpSTCNN/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f89f722-e937-4fa3-ba66-b86308dd09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark(img):\n",
    "    rects = detector(img, 1)\n",
    "    if len(rects) > 1:\n",
    "        pass\n",
    "    if len(rects) == 0:\n",
    "        pass\n",
    "    ans = np.matrix([[p.x, p.y] for p in predictor(img, rects[0]).parts()])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad91798-9910-4270-9ad3-573f898b1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_landmarks(img, landmarks, font_scale = 0.4):\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(img, str(idx), pos, fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=font_scale, color=(0, 0, 255))\n",
    "        cv2.circle(img, pos, 3, color=(0, 255, 255))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfa938-6b48-4455-93aa-c2c95d5b7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = '/Thesis/Sample_dataset/006/006_1_2/006_05626.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a0ff5-1950-4052-8df5-fdcec5564449",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_new = cv2.imread(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6bbec-4f14-48b4-8c39-ec0c53fbad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imshow(image_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddf1f9-b144-4087-b4df-6991fc319ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = get_landmark(image_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67979ee-cf41-4b6b-80ba-c60ae6bcd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpylandmarks = np.asarray(landmarks)\n",
    "eye_image = image_new[numpylandmarks[38][1]-60:numpylandmarks[41][1]+30, numpylandmarks[36][0]-50:numpylandmarks[39][0]+30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e758586-19d0-4802-a30f-1c1b0730e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpylandmarks = np.asarray(landmarks)\n",
    "face = image_new[numpylandmarks[20][1]-40:numpylandmarks[9][1], numpylandmarks[0][0]+30:numpylandmarks[16][0]-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf210f-d563-4374-9b33-ed21ed8f20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4a9c2-90db-49cf-afef-36b73207a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_landmark = np.asarray(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e568390-66e7-4c5b-94d7-15fda8a9bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d2286-6741-4f60-b183-03c2831cc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_image = cv2.resize(eye_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "eye_image = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56862cce-e640-4ba5-b914-6c5619226f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imshow(eye_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78498f1-5b58-42b1-a946-ceaa7184f346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2d4a4-1e1c-454d-84bf-2f3dfbe2b090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5c48a2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Excel to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c404bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Thesis/Datasets/CASME2/CASME2-coding-20190701.xlsx') #index_col=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cfc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a533f-f66e-4fad-8ad0-ad1cf2ea13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Estimated Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fedfb1-7a3c-4dd4-a591-9612ad6f9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecd921-aa8c-484f-a8ae-0ca6092579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Estimated Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba58dfe6-0640-4388-b937-de05ab13c0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>OnsetFrame</th>\n",
       "      <th>ApexFrame</th>\n",
       "      <th>OffsetFrame</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Estimated Emotion</th>\n",
       "      <th>Sub_FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "      <td>1_EP02_01f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EP03_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>others</td>\n",
       "      <td>1_EP03_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>EP04_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>1_EP04_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>EP04_03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>1_EP04_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>EP04_04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>1_EP04_04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  Filename  Unnamed: 2  OnsetFrame ApexFrame  OffsetFrame  \\\n",
       "0       1  EP02_01f         NaN          46        59           86   \n",
       "1       1   EP03_02         NaN         131       139          161   \n",
       "2       1   EP04_02         NaN          21        54           76   \n",
       "3       1   EP04_03         NaN          31        41           56   \n",
       "4       1   EP04_04         NaN          23        49           66   \n",
       "\n",
       "   Unnamed: 6 Action Units Estimated Emotion Sub_FileName  \n",
       "0         NaN           12         happiness   1_EP02_01f  \n",
       "1         NaN           18            others    1_EP03_02  \n",
       "2         NaN            4            others    1_EP04_02  \n",
       "3         NaN            4            others    1_EP04_03  \n",
       "4         NaN            4            others    1_EP04_04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive = df[df['Estimated Emotion'] == 'happiness'][['Subject','Filename']]\n",
    "#print(positive)\n",
    "df['Subject'] = df['Subject'].astype(str)\n",
    "df['Sub_FileName'] = df[['Subject', 'Filename']].apply(lambda x: '_'.join(x), axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed366712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive : 32\n",
      "Negative : 96\n",
      "Surprise : 28\n"
     ]
    }
   ],
   "source": [
    "positive = df[df['Estimated Emotion'] == 'happiness']['Sub_FileName']#[['Subject','Filename']]\n",
    "print('Positive :', positive.count())\n",
    "\n",
    "negative = df[(df['Estimated Emotion'] == 'disgust') | (df['Estimated Emotion'] == 'repression') | (df['Estimated Emotion'] == 'fear') | (df['Estimated Emotion'] == 'sadness')]['Sub_FileName']\n",
    "print('Negative :',negative.count())\n",
    "\n",
    "surprise = df[df['Estimated Emotion'] == 'surprise']['Sub_FileName']\n",
    "print('Surprise :',surprise.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b3cea-9276-4ed1-b6fb-427b69eb3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sub_FileName'].str.split('_')[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44606a5c-f9bb-462f-bfeb-433f742404d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = positive.str.split('_')\n",
    "positive[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb219bd-9da8-4027-9ec1-2fc9161edf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = positive.str.split('_')\n",
    "positive = positive.tolist()\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf9d86-f512-4038-b49e-d61deda09864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sub_FileName'].str.split('_')[9][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189a2a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15212b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectPath = '/Thesis/Datasets/CASME2/CASME2_RAW_selected/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc86eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows, image_columns, frames_Count = 64, 64, 50\n",
    "training_samm_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4f13e-bded-4f08-aa21-1af47eb078b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j, k = 0, 0, 0\n",
    "\n",
    "eye_training_list = []\n",
    "nose_training_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78c589-423c-480e-91c6-d84b87281e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in [positive, surprise]: # negative,\n",
    "    subDirectory = lab#.tolist() \n",
    "    count = 0\n",
    "    for sub in subDirectory:\n",
    "        #labelpath = '/Thesis/Datasets/SAMM/'+ sub[:3] +'/'# + sub + '/'\n",
    "        #print(sub.str.split('_'))\n",
    "        #print(sub)\n",
    "        sub = str(sub).split('_')\n",
    "        #type(sub)\n",
    "        #print(sub)\n",
    "        #print(sub[0].zfill(2))\n",
    "        #print(sub[1]+'_'+sub[2])\n",
    "        #print(sub.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd34db-1574-4c9a-9f72-90ee6164112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j, k = 0, 0, 0\n",
    "\n",
    "eye_training_list = []\n",
    "nose_training_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b84d9-6d51-4b2f-a688-867f14411ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_count = 0\n",
    "for lab in [positive, negative, surprise]: \n",
    "    subDirectory = lab#.tolist() \n",
    "    count = 0\n",
    "    for sub in subDirectory:\n",
    "        sub = str(sub).split('_')\n",
    "        labelpath = '/Thesis/Datasets/CASME2/CASME2_RAW_selected/'+'sub'+ sub[0].zfill(2) +'/'\n",
    "        directorylisting = os.listdir(labelpath)\n",
    "        #print('searching based: ', (sub[1]+'_'+sub[2]))\n",
    "        #print('Existing dir: ',directorylisting[1])\n",
    "    #break\n",
    "        for video in directorylisting:\n",
    "            if video == str(sub[1]+'_'+sub[2]):\n",
    "                #print('Matched dir: ',dirList)\n",
    "                videopath = labelpath + video\n",
    "                frames = []\n",
    "                eye_frames = []\n",
    "                nose_mouth_frames = []\n",
    "                framelisting = os.listdir(videopath)\n",
    "                #loadedvideo = Im.get_reader(videopath, format='FFMPEG' )#, 'ffmpeg')\n",
    "                if len(framelisting) > frames_Count:\n",
    "                    framerange = [x  for x in range(frames_Count)]\n",
    "                    count = count + 1\n",
    "                    for frame in framerange:\n",
    "                        #image = loadedvideo.get_data(frame)\n",
    "                        imagepath = videopath + \"/\" + framelisting[frame]\n",
    "                        image = cv2.imread(imagepath)\n",
    "                    cv2.imshow(image)\n",
    "                        #break\n",
    "            break\n",
    "        break\n",
    "                    \n",
    "                    #     landmarks = get_landmark(image)\n",
    "                    #     numpylandmarks = np.asarray(landmarks)\n",
    "                    #     eye_image = image[numpylandmarks[19][1]:numpylandmarks[1][1], numpylandmarks[1][0]:numpylandmarks[15][0]]\n",
    "                    #     eye_image = cv2.resize(eye_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "                    #     eye_image = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "                    #     nose_mouth_image = image[numpylandmarks[2][1]:numpylandmarks[6][1], numpylandmarks[2][0]:numpylandmarks[14][0]]\n",
    "                    #     nose_mouth_image = cv2.resize(nose_mouth_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "                    #     nose_mouth_image = cv2.cvtColor(nose_mouth_image, cv2.COLOR_BGR2GRAY)\n",
    "                    #     eye_frames.append(eye_image)\n",
    "                    #     nose_mouth_frames.append(nose_mouth_image)\n",
    "                    # eye_frames = np.asarray(eye_frames)\n",
    "                    # nose_mouth_frames = np.asarray(nose_mouth_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104a131-4a7b-49d4-92d9-e4b8b0ac0020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815eee92-92ed-4bd2-91eb-252f4bbaaf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cdc235-ff84-4feb-9d46-7b4cc01ce395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642a3ed-d824-4512-80ff-ff09038a1845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a03793a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CASME-II Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5715265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_count = 0\n",
    "for lab in [positive, negative, surprise]: \n",
    "    subDirectory = lab#.tolist() \n",
    "    count = 0\n",
    "    for sub in subDirectory:\n",
    "        sub = str(sub).split('_')\n",
    "        labelpath = '/Thesis/Datasets/CASME2/CASME2_RAW_selected/'+'sub'+ sub[0].zfill(2) +'/'\n",
    "        directorylisting = os.listdir(labelpath)\n",
    "        #print('searching based: ', (sub[1]+'_'+sub[2]))\n",
    "        #print('Existing dir: ',directorylisting[1])\n",
    "    #break\n",
    "        for video in directorylisting:\n",
    "            if video == str(sub[1]+'_'+sub[2]):\n",
    "                #print('Matched dir: ',dirList)\n",
    "                videopath = labelpath + video\n",
    "                frames = []\n",
    "                eye_frames = []\n",
    "                nose_mouth_frames = []\n",
    "                framelisting = os.listdir(videopath)\n",
    "                #loadedvideo = Im.get_reader(videopath, format='FFMPEG' )#, 'ffmpeg')\n",
    "                if len(framelisting) > frames_Count:\n",
    "                    framerange = [x  for x in range(frames_Count)]\n",
    "                    count = count + 1\n",
    "                    for frame in framerange:\n",
    "                        #image = loadedvideo.get_data(frame)\n",
    "                        imagepath = videopath + \"/\" + framelisting[frame]\n",
    "                        image = cv2.imread(imagepath)\n",
    "                        landmarks = get_landmark(image)\n",
    "                        numpylandmarks = np.asarray(landmarks)\n",
    "                        eye_image = image[numpylandmarks[19][1]:numpylandmarks[1][1], numpylandmarks[1][0]:numpylandmarks[15][0]]\n",
    "                        eye_image = cv2.resize(eye_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "                        eye_image = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "                        nose_mouth_image = image[numpylandmarks[2][1]:numpylandmarks[6][1], numpylandmarks[2][0]:numpylandmarks[14][0]]\n",
    "                        nose_mouth_image = cv2.resize(nose_mouth_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "                        nose_mouth_image = cv2.cvtColor(nose_mouth_image, cv2.COLOR_BGR2GRAY)\n",
    "                        eye_frames.append(eye_image)\n",
    "                        nose_mouth_frames.append(nose_mouth_image)\n",
    "                    eye_frames = np.asarray(eye_frames)\n",
    "                    nose_mouth_frames = np.asarray(nose_mouth_frames)\n",
    "                    eye_videoarray = np.rollaxis(np.rollaxis(eye_frames, 2, 0), 2, 0)\n",
    "                    nose_mouth_videoarray = np.rollaxis(np.rollaxis(nose_mouth_frames, 2, 0), 2, 0)\n",
    "                    eye_training_list.append(eye_videoarray)\n",
    "                    nose_training_list.append(nose_mouth_videoarray)\n",
    "\n",
    "    print(count)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f77d9-22c4-4eea-a580-18ab6d40468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_training_list = np.asarray(eye_training_list)\n",
    "nose_training_list = np.asarray(nose_training_list)\n",
    "\n",
    "eye_trainingsamples = len(eye_training_list)\n",
    "nose_trainingsamples = len(nose_training_list)\n",
    "\n",
    "eye_traininglabels = np.zeros((eye_trainingsamples, ), dtype = int)\n",
    "nose_traininglabels = np.zeros((nose_trainingsamples, ), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850b454-e803-481a-9e48-63aa452a9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "27+75+20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9588ce5-b79b-488c-9b2e-d6c0b32a4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_traininglabels[0:27] = 0\n",
    "eye_traininglabels[27:102] = 1\n",
    "eye_traininglabels[102:122] = 2\n",
    "\n",
    "nose_traininglabels[0:27] = 0\n",
    "nose_traininglabels[27:102] = 1\n",
    "nose_traininglabels[102:122] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65efdd65-1e78-4b3a-a3c5-0683d6ec9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_traininglabels = np_utils.to_categorical(eye_traininglabels, 3)\n",
    "nose_traininglabels = np_utils.to_categorical(nose_traininglabels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e81e7-1ebd-4b2c-826a-8324406d7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "etraining_data = [eye_training_list, eye_traininglabels]\n",
    "(etrainingframes, etraininglabels) = (etraining_data[0], etraining_data[1])\n",
    "etraining_set = np.zeros((eye_trainingsamples, 1, 32, 32, 50))\n",
    "for h in range(eye_trainingsamples):\n",
    "    etraining_set[h][0][:][:][:] = etrainingframes[h,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a459f-8f2f-4a15-bbea-3a5f195c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "etraining_set = etraining_set.astype('float32')\n",
    "etraining_set -= np.mean(etraining_set)\n",
    "etraining_set /= np.max(etraining_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e75de-9674-48cd-a037-eebf76b352a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntraining_data = [nose_training_list, nose_traininglabels]\n",
    "(ntrainingframes, ntraininglabels) = (ntraining_data[0], ntraining_data[1])\n",
    "ntraining_set = np.zeros((nose_trainingsamples, 1, 32, 32, 50))\n",
    "for h in range(nose_trainingsamples):\n",
    "        ntraining_set[h][0][:][:][:] = ntrainingframes[h,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f62ed-1225-48ce-a7cb-078fd3a45e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntraining_set = ntraining_set.astype('float32')\n",
    "ntraining_set -= np.mean(ntraining_set)\n",
    "ntraining_set /= np.max(ntraining_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518176de-07a1-4000-8e73-4277bc9d99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfusenetnoseimages.npy', ntraining_set)\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfuseneteyeimages.npy', etraining_set)\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfusenetnoselabels.npy', nose_traininglabels)\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfuseneteyelabels.npy', eye_traininglabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5e198-06d2-4899-a001-e3b943d1d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images and labels that are stored in numpy array\n",
    "\n",
    "ntraining_set = np.load('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfusenetnoseimages.npy')\n",
    "etraining_set = np.load('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfuseneteyeimages.npy')\n",
    "eye_traininglabels = np.load('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfusenetnoselabels.npy')\n",
    "nose_traininglabels = np.load('/Thesis/MicroExpSTCNN/Training_dataset_CASME/intermediate_microexpfuseneteyelabels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da006e8b-8d05-4a22-8bde-8da9b48cd089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate MicroExpFuseNet Model\n",
    "eye_input = Input(shape = (1, 32, 32, 50))\n",
    "eye_conv = Convolution3D(32, (3, 3, 15))(eye_input)\n",
    "ract_1 = Activation('relu')(eye_conv)\n",
    "eye_max = MaxPooling3D(pool_size=(3, 3, 3))(ract_1)\n",
    "dropout_1 = Dropout(0.5)(eye_max)\n",
    "eye_flatten = Flatten()(dropout_1)\n",
    "\n",
    "nose_input = Input(shape = (1, 32, 32, 50))\n",
    "nose_conv = Convolution3D(32, (3, 3, 15))(nose_input)\n",
    "ract_2 = Activation('relu')(nose_conv)\n",
    "nose_max = MaxPooling3D(pool_size=(3, 3, 3))(ract_2)\n",
    "dropout_2 = Dropout(0.5)(nose_max)\n",
    "nose_flatten = Flatten()(dropout_2)\n",
    "\n",
    "result = Concatenate(axis = 1)([eye_flatten, nose_flatten])\n",
    "dense_1 = Dense(1024, )(result)\n",
    "dropout_4 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(128, )(dropout_4)\n",
    "dropout_5 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(3, )(dropout_5)\n",
    "activation = Activation('softmax')(dense_3)\n",
    "\n",
    "model = Model(inputs = [eye_input, nose_input], outputs = activation)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
    "\n",
    "filepath=\"weights_IF/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc58bd-7573-4f5c-82cf-eaa286f49b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained weights\n",
    "#model.load_weights('weights_intermediate_microexpfusenet/weights-improvement-22-0.83.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e235a4f-17ea-4dfa-b4b3-86024256b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into training and validation sets\n",
    "etrain_images, evalidation_images, etrain_labels, evalidation_labels =  train_test_split(etraining_set, eye_traininglabels, test_size=0.2, shuffle=False)\n",
    "ntrain_images, nvalidation_images, ntrain_labels, nvalidation_labels =  train_test_split(ntraining_set, nose_traininglabels, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a2370-7886-45d7-9105-d04b95fca0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation set in a numpy array\n",
    "np.save('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_eval_images.npy', evalidation_images)\n",
    "np.save('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_nval_images.npy', nvalidation_images)\n",
    "np.save('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_eval_labels.npy', evalidation_labels)\n",
    "np.save('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_nval_labels.npy', nvalidation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7deaa5-0674-419a-b626-023a38030e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit([etrain_images, ntrain_images], etrain_labels, validation_data = ([evalidation_images, nvalidation_images], evalidation_labels), callbacks=callbacks_list, batch_size = 16, epochs = 100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77bab0-4610-4b8b-ab56-9ffed156f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Load validation set from numpy array\n",
    "eimg = np.load('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_eval_images.npy')\n",
    "nimg = np.load('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_nval_images.npy')\n",
    "labels = np.load('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_eval_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8cf07-0546-4f02-96ba-c908f25d23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion Matrix using pretrained weights\n",
    "predictions = model.predict([eimg, nimg])\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "validation_labels = np.argmax(labels, axis=1)\n",
    "cfm = confusion_matrix(validation_labels, predictions_labels)\n",
    "print (cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f4b3c-dfd8-47a4-b791-c94c5cdb4643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
