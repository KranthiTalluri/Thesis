{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5258058e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3488caa-5a30-4876-b352-5ae8a93afcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import imageio\n",
    "# from imageio import v3 as Im\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "# from keras.optimizers import SGD, RMSprop\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.utils import np_utils, generic_utils\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn import preprocessing\n",
    "# from keras import backend as K\n",
    "# import sys\n",
    "# import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pylab\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import skimage.io as imageio\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "#from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate, Input, concatenate, add, multiply, maximum, LSTM, Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#K.set_image_dim_ordering('th')\n",
    "#K.set_image_data_format('channels_first')\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ca99e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4776d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afb8ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f82c1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff91c2d-6d23-4632-862b-3ea95e1b8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_image_dim_ordering('th')\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189a2a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27ac1c42-d53f-4da0-aac8-2a66e6b4f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = \"/Thesis/MicroExpSTCNN/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ea3e88-9325-49de-9db5-0888c56b6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark(img):\n",
    "    rects = detector(img, 1)\n",
    "    if len(rects) > 1:\n",
    "        pass\n",
    "    if len(rects) == 0:\n",
    "        pass\n",
    "    ans = np.matrix([[p.x, p.y] for p in predictor(img, rects[0]).parts()])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d081753-4561-4a7b-a260-f39540b4eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_landmarks(img, landmarks, font_scale = 0.4):\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(img, str(idx), pos, fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=font_scale, color=(0, 0, 255))\n",
    "        cv2.circle(img, pos, 3, color=(0, 255, 255))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15212b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectPath = '/Thesis/Datasets/SMIC/HS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfc86eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows, image_columns, frames_Count = 64, 64, 16\n",
    "training_smic_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a03793a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SMIC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5715265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for lab in ['negative', 'positive', 'surprise']:\n",
    "    subDirectory = os.listdir(subjectPath)\n",
    "    count = 0\n",
    "    for sub in tqdm(subDirectory):\n",
    "        labelpath = '/Thesis/Datasets/SMIC/HS/'+ sub +'/micro/' + lab + '/'\n",
    "        directorylisting = os.listdir(labelpath)\n",
    "        for video in directorylisting:\n",
    "            videopath = labelpath + video\n",
    "            frames = []\n",
    "            framelisting = os.listdir(videopath)\n",
    "            if len(framelisting) > frames_Count:\n",
    "                framerange = [x for x in range(frames_Count)]\n",
    "                count = count + 1\n",
    "                for frame in framerange:\n",
    "                    imagepath = videopath + \"/\" + framelisting[frame]\n",
    "                    image = cv2.imread(imagepath)\n",
    "                    imageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
    "                    grayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
    "                    frames.append(grayimage)\n",
    "                frames = np.asarray(frames)\n",
    "                videoarray = np.rollaxis(np.rollaxis(frames, 2, 0), 2, 0)\n",
    "                training_smic_list.append(videoarray)\n",
    "                # break\n",
    "    print(lab,count)\n",
    "    # break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0526a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_smic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee108b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "66+50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adb646",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Creating Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379871d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_smic_list = np.asarray(training_smic_list)\n",
    "training_smic_samples = len(training_smic_list)\n",
    "\n",
    "training_smic_labels = np.zeros((training_smic_samples, ), dtype = int)\n",
    "\n",
    "training_smic_labels[0:66] = 0\n",
    "training_smic_labels[66:116] = 1\n",
    "training_smic_labels[116:159] = 2\n",
    "\n",
    "training_smic_labels = np_utils.to_categorical(training_smic_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4745f-6e6d-4000-b378-abfa73689d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_smic_data = [training_smic_list, training_smic_labels]\n",
    "(training_frames_samm, traininglabels_samm) = (training_smic_data[0], training_smic_data[1])\n",
    "training_smic_set = np.zeros((training_smic_samples, 1, image_rows, image_columns, frames_Count))\n",
    "\n",
    "for h in range(training_smic_samples):\n",
    "    training_smic_set[h][0][:][:][:] = training_frames_samm[h,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbcd11f-857c-411e-8ef2-4f42e4c84ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_smic_set = training_smic_set.astype('float32')\n",
    "training_smic_set -= np.mean(training_smic_set)\n",
    "training_smic_set /= np.max(training_smic_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_smic_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed54da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Nump Arrays to save time\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset/microexp_smic_images.npy', training_smic_set)\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset/microexp_smic_labels.npy', training_smic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e6e89",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loading Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e4dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_smic_set = None\n",
    "training_smic_labels = None\n",
    "training_smic_set  = np.load('/Thesis/MicroExpSTCNN/Training_dataset/microexp_smic_images.npy')\n",
    "training_smic_labels = np.load('/Thesis/MicroExpSTCNN/Training_dataset/microexp_smic_labels.npy')\n",
    "\n",
    "training_smic_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee2992-0b6b-4542-bf33-32e6ab8d9c1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e177ced-d4eb-4004-8fbf-aa1609d1fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution3D(32, (3, 3, 15), input_shape=(1, image_rows, image_columns, frames_Count), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd97a8-872f-4d11-98d4-62d810658b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained weights\n",
    "\n",
    "#model.load_weights('/Thesis/MicroExpSTCNN/Training_dataset/weights_microexpstcnn/weights-improvement-53-0.88.hdf5')\n",
    "\n",
    "#model.load_weights('/Thesis/MicroExpSTCNN/CASME_SQUARE/weights-improvement-53-0.88.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db381c68-91cc-4952-ab00-b3bfc56c9e2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Creating checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22e16a-8566-41f6-acc1-de5461aa377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"/Thesis/MicroExpSTCNN/Training_dataset_smic/weights_microexpstcnn_smic/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ebf60-8672-496d-8826-d2aeffb3613f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spliting the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f58faf-02e2-4c4e-a119-0237d4a01c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, train_labels, validation_labels =  train_test_split(training_smic_set, training_smic_labels, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9377792-a982-44da-b41e-205dc1c1728e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save validation set in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8f595-6f21-4706-8d48-ac2ef4dd8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset_smic/microexpstcnn_val_images.npy', validation_images)\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset_smic/microexpstcnn_val_labels.npy', validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01c86c-82f3-46e8-8691-c8b76858d7a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load validation set from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8e320-8ec7-4748-ab3c-d283cb654d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = np.load('/Thesis/MicroExpSTCNN/Training_dataset_smic/microexpstcnn_val_images.npy')\n",
    "validation_labels = np.load('/Thesis/MicroExpSTCNN/Training_dataset_smic/microexpstcnn_val_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b06b58-41b5-47bb-89d5-33ce2d8bcb52",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pre-Trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac83ae-6a53-419e-b8b0-593793ccc2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_images = np.load('/Thesis/MicroExpSTCNN/CASME_SQUARE/microexpstcnn_val_images.npy')\n",
    "#validation_labels = np.load('/Thesis/MicroExpSTCNN/CASME_SQUARE/microexpstcnn_val_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eeb2e1-108d-4fca-b6cc-9ffced1640ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd79389-9297-4c36-ab36-be7aac19f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_images, train_labels, validation_data = (validation_images, validation_labels), callbacks=callbacks_list, batch_size = 16, epochs = 100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8e6d1-f5bc-499e-a418-ed1050cd422e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Finding Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe846821-c995-4317-8ada-e07ae2e2cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_images)\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "validation_labels = np.argmax(validation_labels, axis=1)\n",
    "cfm = confusion_matrix(validation_labels, predictions_labels)\n",
    "print (cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568e192-31d5-49be-b5ea-17fb08090fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
