{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5258058e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd7f212-e02d-46e3-9235-f24bce2fcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pylab\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import skimage.io as imageio\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "#from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate, Input, concatenate, add, multiply, maximum, LSTM, Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#K.set_image_dim_ordering('th')\n",
    "#K.set_image_data_format('channels_first')\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ca99e",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4776d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afb8ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f82c1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46298de4-7e39-490a-8705-9ab49e99461b",
   "metadata": {},
   "source": [
    "### DLib Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1321c0-b8a5-4531-a3fa-53984aad7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = \"/Thesis/MicroExpSTCNN/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89f722-e937-4fa3-ba66-b86308dd09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark(img):\n",
    "    rects = detector(img, 1)\n",
    "    if len(rects) > 1:\n",
    "        pass\n",
    "    if len(rects) == 0:\n",
    "        pass\n",
    "    ans = np.matrix([[p.x, p.y] for p in predictor(img, rects[0]).parts()])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad91798-9910-4270-9ad3-573f898b1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_landmarks(img, landmarks, font_scale = 0.4):\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(img, str(idx), pos, fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=font_scale, color=(0, 0, 255))\n",
    "        cv2.circle(img, pos, 3, color=(0, 255, 255))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfa938-6b48-4455-93aa-c2c95d5b7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = '/Thesis/Sample_dataset/006/006_1_2/006_05626.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a0ff5-1950-4052-8df5-fdcec5564449",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_new = cv2.imread(new_path)\n",
    "image_new = cv2.cvtColor(image_new, cv2.COLOR_BGR2GRAY)\n",
    "image_new = np.expand_dims(image_new, axis=2)\n",
    "image_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6bbec-4f14-48b4-8c39-ec0c53fbad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imshow(image_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddf1f9-b144-4087-b4df-6991fc319ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = get_landmark(image_new)\n",
    "numpylandmarks = np.asarray(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2d04d-8dda-4fb2-9a5b-bbcb9f4e70fe",
   "metadata": {},
   "source": [
    "### Cropping of parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e758586-19d0-4802-a30f-1c1b0730e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_face = image_new[numpylandmarks[20][1]-40:numpylandmarks[9][1]-30, numpylandmarks[0][0]+30:numpylandmarks[16][0]-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67979ee-cf41-4b6b-80ba-c60ae6bcd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_image = image_new[numpylandmarks[38][1]-60:numpylandmarks[41][1]+30, numpylandmarks[36][0]-50:numpylandmarks[39][0]+30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fa2b3-383d-4281-94ca-a178a7c7f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_eye_image = image_new[numpylandmarks[43][1]-60:numpylandmarks[46][1]+30, numpylandmarks[42][0]-40:numpylandmarks[45][0]+40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c554c-bc2d-4869-a26b-5a284061460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouth_image = image_new[numpylandmarks[2][1]+20:numpylandmarks[6][1]-30, numpylandmarks[2][0]+70:numpylandmarks[14][0]-80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf210f-d563-4374-9b33-ed21ed8f20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imshow(mouth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ecf6ab-20f2-40f5-b8b5-7d5dfad1d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac2bc0-1ccb-41d4-9dec-251d3b75eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelpath = '/Thesis/Sample_dataset/'\n",
    "directorylisting = os.listdir(labelpath)\n",
    "print(directorylisting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87f36d-48cf-411f-a954-0cfaea02a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_Count = 5\n",
    "labelpath = '/Thesis/Sample_dataset/'\n",
    "directorylisting = os.listdir(labelpath)\n",
    "for video in directorylisting:\n",
    "    frames = []\n",
    "    count = 0\n",
    "    left_eye_frames = []\n",
    "    videopath = labelpath + video + '/'\n",
    "    Num_videos = os.listdir(videopath)\n",
    "    for vd in Num_videos:\n",
    "        framepath = videopath + vd\n",
    "        framelisting = os.listdir(framepath)\n",
    "        count = count+1\n",
    "        if len(framelisting) > frames_Count:\n",
    "            print('Video :  ',vd, '        Number of frames : ',len(framelisting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad740fe-a9ce-490c-bede-2a58bcf1fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_Count = 5\n",
    "left_eye_training_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c99e5-71ef-48a3-ae51-01bebcc92dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelpath = '/Thesis/Sample_dataset/'\n",
    "directorylisting = os.listdir(labelpath)\n",
    "for sub in directorylisting:\n",
    "    count = 0\n",
    "    sub_path = labelpath + sub + '/'\n",
    "    num_videos = os.listdir(sub_path)\n",
    "    for vd in num_videos:\n",
    "        framepath = sub_path + vd\n",
    "        frames = []\n",
    "        left_eye_frames = []\n",
    "        framelisting = os.listdir(framepath)\n",
    "        count = count+1\n",
    "        if len(framelisting) > frames_Count:\n",
    "            #print('Video :  ',vd, '        Number of frames : ',len(framelisting))\n",
    "            framerange = [x  for x in range(frames_Count)]\n",
    "            for frame in framerange:\n",
    "                imagepath = framepath + '/' + framelisting[frame]\n",
    "                image = cv2.imread(imagepath)\n",
    "                landmarks = get_landmark(image)\n",
    "                numpylandmarks = np.asarray(landmarks)\n",
    "                left_eye_image = image[numpylandmarks[38][1]-60:numpylandmarks[41][1]+30, numpylandmarks[36][0]-50:numpylandmarks[39][0]+30]\n",
    "                left_eye_image = cv2.resize(left_eye_image, (40, 50), interpolation = cv2.INTER_AREA)\n",
    "                left_eye_image = cv2.cvtColor(left_eye_image, cv2.COLOR_BGR2GRAY)\n",
    "                left_eye_image = np.expand_dims(left_eye_image, axis=2)\n",
    "                left_eye_frames.append(left_eye_image)\n",
    "            left_eye_frames = np.asarray(left_eye_frames)\n",
    "            #left_eye_videoarray = np.rollaxis(np.rollaxis(left_eye_frames, 2, 0), 2, 0)\n",
    "            left_eye_training_list.append(left_eye_frames)\n",
    "\n",
    "#     print(count)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741eca6-d36b-44fe-b070-4c19a9580c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_training_list[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c48a2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Excel to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Thesis/Datasets/CASME2/CASME2-coding-20190701.xlsx') #index_col=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cfc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecd921-aa8c-484f-a8ae-0ca6092579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Estimated Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58dfe6-0640-4388-b937-de05ab13c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subject'] = df['Subject'].astype(str)\n",
    "df['Sub_FileName'] = df[['Subject', 'Filename']].apply(lambda x: '_'.join(x), axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed366712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive = df[df['Estimated Emotion'] == 'happiness']['Sub_FileName']#[['Subject','Filename']]\n",
    "print('Positive :', positive.count())\n",
    "\n",
    "negative = df[(df['Estimated Emotion'] == 'disgust') | (df['Estimated Emotion'] == 'repression') | (df['Estimated Emotion'] == 'fear') | (df['Estimated Emotion'] == 'sadness')]['Sub_FileName']\n",
    "print('Negative :',negative.count())\n",
    "\n",
    "surprise = df[df['Estimated Emotion'] == 'surprise']['Sub_FileName']\n",
    "print('Surprise :',surprise.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189a2a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15212b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectPath = '/Thesis/Datasets/CASME2/CASME2_RAW_selected/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea7c77-e08b-4668-84d1-edd7edcbe53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j, k = 0, 0, 0\n",
    "\n",
    "frames_Count = 48\n",
    "left_eye_training_list = []\n",
    "right_eye_training_list = []\n",
    "mouth_training_list = []\n",
    "total_face_training_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a03793a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CASME-II Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5715265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_count = 0\n",
    "for lab in [positive, negative, surprise]: \n",
    "    subDirectory = lab#.tolist() \n",
    "    count = 0\n",
    "    for sub in tqdm(subDirectory):\n",
    "        sub = str(sub).split('_')\n",
    "        labelpath = '/Thesis/Datasets/CASME2/CASME2_RAW_selected/'+'sub'+ sub[0].zfill(2) +'/'\n",
    "        directorylisting = os.listdir(labelpath)\n",
    "        for video in directorylisting:\n",
    "            if video == str(sub[1]+'_'+sub[2]):\n",
    "                frames = []\n",
    "                left_eye_frames = []\n",
    "                right_eye_frames = []\n",
    "                mouth_frames = []\n",
    "                total_face_frames = []\n",
    "                videopath = labelpath + video\n",
    "                framelisting = os.listdir(videopath)\n",
    "                if len(framelisting) > frames_Count:\n",
    "                    framerange = [x  for x in range(frames_Count)]\n",
    "                    count = count + 1\n",
    "                    for frame in framerange:\n",
    "                        imagepath = videopath + \"/\" + framelisting[frame]\n",
    "                        image = cv2.imread(imagepath)\n",
    "                        landmarks = get_landmark(image)\n",
    "                        numpylandmarks = np.asarray(landmarks)\n",
    "                        \n",
    "                        left_eye_image = image[numpylandmarks[38][1]-60:numpylandmarks[41][1]+30, numpylandmarks[36][0]-50:numpylandmarks[39][0]+30]\n",
    "                        left_eye_image = cv2.resize(left_eye_image, (40, 50), interpolation = cv2.INTER_AREA)\n",
    "                        left_eye_image = cv2.cvtColor(left_eye_image, cv2.COLOR_BGR2GRAY)\n",
    "                        left_eye_image = np.expand_dims(left_eye_image, axis=2)\n",
    "                        \n",
    "                        right_eye_image = image[numpylandmarks[43][1]-60:numpylandmarks[46][1]+30, numpylandmarks[42][0]-40:numpylandmarks[45][0]+40]\n",
    "                        right_eye_image = cv2.resize(right_eye_image, (40, 50), interpolation = cv2.INTER_AREA)\n",
    "                        right_eye_image = cv2.cvtColor(right_eye_image, cv2.COLOR_BGR2GRAY)\n",
    "                        right_eye_image = np.expand_dims(right_eye_image, axis=2)\n",
    "                        \n",
    "                        mouth_image = image[numpylandmarks[2][1]+20:numpylandmarks[6][1]-30, numpylandmarks[2][0]+70:numpylandmarks[14][0]-80]\n",
    "                        mouth_image = cv2.resize(mouth_image, (80, 30), interpolation = cv2.INTER_AREA)\n",
    "                        mouth_image = cv2.cvtColor(mouth_image, cv2.COLOR_BGR2GRAY)\n",
    "                        mouth_image = np.expand_dims(mouth_image, axis=2)\n",
    "                        \n",
    "                        total_face_image = image[numpylandmarks[20][1]-40:numpylandmarks[9][1]-30, numpylandmarks[0][0]+30:numpylandmarks[16][0]-30]\n",
    "                        total_face_image = cv2.resize(total_face_image, (140, 120), interpolation = cv2.INTER_AREA)\n",
    "                        total_face_image = cv2.cvtColor(total_face_image, cv2.COLOR_BGR2GRAY)\n",
    "                        total_face_image = np.expand_dims(total_face_image, axis=2)\n",
    "                        \n",
    "                        left_eye_frames.append(left_eye_image)\n",
    "                        right_eye_frames.append(right_eye_image)\n",
    "                        mouth_frames.append(mouth_image)\n",
    "                        total_face_frames.append(total_face_image)\n",
    "                        \n",
    "                    left_eye_frames = np.asarray(left_eye_frames)\n",
    "                    right_eye_frames = np.asarray(right_eye_frames)\n",
    "                    mouth_frames = np.asarray(mouth_frames)\n",
    "                    total_face_frames = np.asarray(total_face_frames)\n",
    "\n",
    "                    # left_eye_videoarray = np.rollaxis(np.rollaxis(left_eye_frames, 2, 0), 2, 0)\n",
    "                    # right_eye_videoarray = np.rollaxis(np.rollaxis(right_eye_frames, 2, 0), 2, 0)\n",
    "                    # mouth_videoarray = np.rollaxis(np.rollaxis(mouth_frames, 2, 0), 2, 0)\n",
    "                    # total_face_videoarray = np.rollaxis(np.rollaxis(total_face_frames, 2, 0), 2, 0)\n",
    "\n",
    "                    left_eye_training_list.append(left_eye_frames)\n",
    "                    right_eye_training_list.append(right_eye_frames)\n",
    "                    mouth_training_list.append(mouth_frames)\n",
    "                    total_face_training_list.append(total_face_frames)\n",
    "                    #break\n",
    "\n",
    "    print(count)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1099be-5fce-4f83-8fef-cffce4fe08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_face_videoarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c51e1-1b76-44d2-9019-8aa92d9d38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mouth_training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff072632-ef68-4f17-9f0b-8157508406ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_face_training_list[122].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f77d9-22c4-4eea-a580-18ab6d40468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_training_list = np.asarray(left_eye_training_list)\n",
    "right_eye_training_list = np.asarray(right_eye_training_list)\n",
    "mouth_training_list = np.asarray(mouth_training_list)\n",
    "total_face_training_list = np.asarray(total_face_training_list)\n",
    "\n",
    "left_eye_trainingsamples = len(left_eye_training_list)\n",
    "right_eye_trainingsamples = len(right_eye_training_list)\n",
    "mouth_trainingsamples = len(mouth_training_list)\n",
    "total_face_trainingsamples = len(total_face_training_list)\n",
    "\n",
    "left_eye_traininglabels = np.zeros((left_eye_trainingsamples, ), dtype = int)\n",
    "right_eye_traininglabels = np.zeros((right_eye_trainingsamples, ), dtype = int)\n",
    "mouth_traininglabels = np.zeros((mouth_trainingsamples, ), dtype = int)\n",
    "total_face_traininglabels = np.zeros((total_face_trainingsamples, ), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850b454-e803-481a-9e48-63aa452a9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "27+76+21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9588ce5-b79b-488c-9b2e-d6c0b32a4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_traininglabels[0:27] = 0\n",
    "left_eye_traininglabels[27:103] = 1\n",
    "left_eye_traininglabels[103:124] = 2\n",
    "\n",
    "right_eye_traininglabels[0:27] = 0\n",
    "right_eye_traininglabels[27:103] = 1\n",
    "right_eye_traininglabels[103:124] = 2\n",
    "\n",
    "mouth_traininglabels[0:27] = 0\n",
    "mouth_traininglabels[27:103] = 1\n",
    "mouth_traininglabels[103:124] = 2\n",
    "\n",
    "total_face_traininglabels[0:27] = 0\n",
    "total_face_traininglabels[27:103] = 1\n",
    "total_face_traininglabels[103:124] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65efdd65-1e78-4b3a-a3c5-0683d6ec9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_eye_traininglabels = np_utils.to_categorical(left_eye_traininglabels, 3)\n",
    "# right_eye_traininglabels = np_utils.to_categorical(right_eye_traininglabels, 3)\n",
    "# mouth_traininglabels = np_utils.to_categorical(mouth_traininglabels, 3)\n",
    "# total_face_traininglabels = np_utils.to_categorical(total_face_traininglabels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e81e7-1ebd-4b2c-826a-8324406d7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_training_data = [left_eye_training_list, left_eye_traininglabels]\n",
    "(left_eye_training_set, left_eye_traininglabels) = (left_eye_training_data[0], left_eye_training_data[1])\n",
    "# left_eye_training_set = np.zeros((left_eye_trainingsamples, 48, 50, 40, 1))\n",
    "# for h in range(left_eye_trainingsamples):\n",
    "#     left_eye_training_set[h][:][:][:][:][0] = left_eye_trainingframes[h,:,:,:]\n",
    "#     print(left_eye_training_set)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265bcaa-2056-4133-b78b-56be6b7f6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_training_set = left_eye_training_set.astype('float32')\n",
    "left_eye_training_set -= np.mean(left_eye_training_set)\n",
    "left_eye_training_set /= np.max(left_eye_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bf84f-0267-4833-912d-10fcdd4bb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_eye_training_data = [right_eye_training_list, right_eye_traininglabels]\n",
    "(right_eye_training_set, right_eye_traininglabels) = (right_eye_training_data[0], right_eye_training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3167859-8460-42f1-8469-8270b1c53c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_eye_training_set = right_eye_training_set.astype('float32')\n",
    "right_eye_training_set -= np.mean(right_eye_training_set)\n",
    "right_eye_training_set /= np.max(right_eye_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e0007-f52f-4aff-8870-66e6cf8b01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouth_training_data = [mouth_training_list, mouth_traininglabels]\n",
    "(mouth_training_set, mouth_traininglabels) = (mouth_training_data[0], mouth_training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab1f9f-f5b3-463e-9640-207292eed5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouth_training_set = mouth_training_set.astype('float32')\n",
    "mouth_training_set -= np.mean(mouth_training_set)\n",
    "mouth_training_set /= np.max(mouth_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53bb99-3f0a-41ad-bbdf-56eb0278bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_face_training_data = [total_face_training_list, total_face_traininglabels]\n",
    "(total_face_training_set, total_face_traininglabels) = (total_face_training_data[0], total_face_training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ce1b4-6de5-4eea-8970-c552fa35fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_face_training_set = total_face_training_set.astype('float32')\n",
    "total_face_training_set -= np.mean(total_face_training_set)\n",
    "total_face_training_set /= np.max(total_face_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518176de-07a1-4000-8e73-4277bc9d99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/left_eye_images.npy', left_eye_training_set)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/left_eye_labels.npy', left_eye_traininglabels)\n",
    "\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/right_eye_images.npy', right_eye_training_set)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/right_eye_labels.npy', right_eye_traininglabels)\n",
    "\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/mouth_images.npy', mouth_training_set)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/mouth_labels.npy', mouth_traininglabels)\n",
    "\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/face_images.npy', total_face_training_set)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/face_labels.npy', total_face_traininglabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb5e198-06d2-4899-a001-e3b943d1d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images and labels that are stored in numpy array\n",
    "\n",
    "left_eye_training_set = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/left_eye_images.npy')\n",
    "left_eye_traininglabels = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/left_eye_labels.npy')\n",
    "\n",
    "right_eye_training_set = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/right_eye_images.npy')\n",
    "right_eye_traininglabels = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/right_eye_labels.npy')\n",
    "\n",
    "mouth_training_set = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/mouth_images.npy')\n",
    "mouth_traininglabels = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/mouth_labels.npy')\n",
    "\n",
    "total_face_training_set = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/face_images.npy')\n",
    "total_face_traininglabels = np.load('/Thesis/Multi_Scale_MicroExp/Training_dataset_CASME/face_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545687be-38f6-457a-a813-de77c4b4188a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 48, 30, 80, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouth_training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ebd83-171f-4dea-b5e6-2f57701d75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_input = Input(shape = (48, 30, 80, 1))\n",
    "face_conv = Convolution3D(16, (3, 3, 3))(face_input)\n",
    "face_ract_1 = Activation('relu')(face_conv)\n",
    "face_max = MaxPooling3D(pool_size=(3, 3, 3))(face_ract_1)\n",
    "print(face_max.shape)\n",
    "# face_reshape = tf.keras.layers.Reshape((4, 39 * 46 * 16))(face_max)\n",
    "# face_lstm = tf.keras.layers.LSTM(units = 512)(face_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd0e75-7bc4-46d6-9b61-5a5abc3022e0",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da006e8b-8d05-4a22-8bde-8da9b48cd089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 50, 40,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 48, 50, 40,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 48, 30, 80,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 48, 120, 140 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 46, 48, 38, 1 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 46, 48, 38, 1 448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 46, 28, 78, 1 448         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 46, 118, 138, 448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 46, 48, 38, 1 0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 46, 48, 38, 1 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 46, 28, 78, 1 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 46, 118, 138, 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 15, 16, 12, 1 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 15, 16, 12, 1 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 15, 9, 26, 16 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 15, 39, 46, 1 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 15, 3072)     0           max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 15, 3072)     0           max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 15, 3744)     0           max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 15, 28704)    0           max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 512)          7342080     reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 512)          7342080     reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 512)          8718336     reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 512)          59836416    reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 512)          0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 512)          0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          131200      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            387         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 3)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 85,470,467\n",
      "Trainable params: 85,470,467\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_eye_input = Input(shape = (48, 50, 40, 1))\n",
    "left_eye_conv = Convolution3D(16, (3, 3, 3))(left_eye_input)\n",
    "left_ract_1 = Activation('relu')(left_eye_conv)\n",
    "left_eye_max = MaxPooling3D(pool_size=(3, 3, 3))(left_ract_1)\n",
    "left_eye_reshape = tf.keras.layers.Reshape((15, 16 * 12 * 16))(left_eye_max)\n",
    "left_eye_lstm = tf.keras.layers.LSTM(units = 512)(left_eye_reshape)\n",
    "#left_dropout_1 = Dropout(0.5)(left_eye_max)\n",
    "left_eye_flatten = Flatten()(left_eye_lstm)\n",
    "\n",
    "right_eye_input = Input(shape = (48, 50, 40, 1))\n",
    "right_eye_conv = Convolution3D(16, (3, 3, 3))(right_eye_input)\n",
    "right_ract_1 = Activation('relu')(right_eye_conv)\n",
    "right_eye_max = MaxPooling3D(pool_size=(3, 3, 3))(right_ract_1)\n",
    "right_eye_reshape = tf.keras.layers.Reshape((15, 16 * 12 * 16))(right_eye_max)\n",
    "right_eye_lstm = tf.keras.layers.LSTM(units = 512)(right_eye_reshape)\n",
    "#right_dropout_1 = Dropout(0.5)(right_eye_max)\n",
    "right_eye_flatten = Flatten()(right_eye_lstm)\n",
    "\n",
    "mouth_input = Input(shape = (48, 30, 80, 1))\n",
    "mouth_conv = Convolution3D(16, (3, 3, 3))(mouth_input)\n",
    "mouth_ract_1 = Activation('relu')(mouth_conv)\n",
    "mouth_max = MaxPooling3D(pool_size=(3, 3, 3))(mouth_ract_1)\n",
    "mouth_reshape = tf.keras.layers.Reshape((15, 9 * 26 * 16))(mouth_max)\n",
    "mouth_lstm = tf.keras.layers.LSTM(units = 512)(mouth_reshape)\n",
    "#mouth_dropout_1 = Dropout(0.5)(mouth_max)\n",
    "mouth_flatten = Flatten()(mouth_lstm)\n",
    "\n",
    "face_input = Input(shape = (48, 120, 140, 1))\n",
    "face_conv = Convolution3D(16, (3, 3, 3))(face_input)\n",
    "face_ract_1 = Activation('relu')(face_conv)\n",
    "face_max = MaxPooling3D(pool_size=(3, 3, 3))(face_ract_1)\n",
    "face_reshape = tf.keras.layers.Reshape((15, 39 * 46 * 16))(face_max)\n",
    "face_lstm = tf.keras.layers.LSTM(units = 512)(face_reshape)\n",
    "#face_dropout_1 = Dropout(0.5)(face_max)\n",
    "face_flatten = Flatten()(face_lstm)\n",
    "\n",
    "result = Concatenate(axis = 1)([left_eye_flatten, right_eye_flatten, mouth_flatten, face_flatten])\n",
    "dense_1 = Dense(1024, )(result)\n",
    "dropout_4 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(128, )(dropout_4)\n",
    "dropout_5 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(3, )(dropout_5)\n",
    "activation = Activation('softmax')(dense_3)\n",
    "\n",
    "model = Model(inputs = [left_eye_input, right_eye_input, mouth_input, face_input], outputs = activation)\n",
    "\n",
    "#model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
    "\n",
    "filepath=\"weights_IF/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc58bd-7573-4f5c-82cf-eaa286f49b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained weights\n",
    "#model.load_weights('weights_intermediate_microexpfusenet/weights-improvement-22-0.83.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e235a4f-17ea-4dfa-b4b3-86024256b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into training and validation sets\n",
    "le_train_images, le_validation_images, le_train_labels, le_validation_labels =  train_test_split(left_eye_training_set, left_eye_traininglabels, test_size=0.2, shuffle=False)\n",
    "re_train_images, re_validation_images, re_train_labels, re_validation_labels =  train_test_split(right_eye_training_set, right_eye_traininglabels, test_size=0.2, shuffle=False)\n",
    "m_train_images, m_validation_images, m_train_labels, m_validation_labels =  train_test_split(mouth_training_set, mouth_traininglabels, test_size=0.2, shuffle=False)\n",
    "f_train_images, f_validation_images, f_train_labels, f_validation_labels =  train_test_split(total_face_training_set, total_face_traininglabels, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a2370-7886-45d7-9105-d04b95fca0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation set in a numpy array\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/le_val_images.npy', le_validation_images)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/le_val_labels.npy', le_validation_labels)\n",
    "\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/re_val_images.npy', re_validation_images)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/re_val_labels.npy', re_validation_labels)\n",
    "\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/m_val_images.npy', m_validation_images)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/m_val_labels.npy', m_validation_labels)\n",
    "\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/f_val_images.npy', f_validation_images)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/validation_data_CASME/f_val_labels.npy', f_validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7deaa5-0674-419a-b626-023a38030e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "#history = model.fit([le_train_images, re_train_images, m_train_images, f_train_images], le_train_labels, validation_data = ([le_validation_images, re_validation_images, m_validation_images, f_validation_images], le_validation_labels), callbacks=callbacks_list, batch_size = 16, epochs = 300, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77bab0-4610-4b8b-ab56-9ffed156f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Load validation set from numpy array\n",
    "eimg = np.load('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_eval_images.npy')\n",
    "nimg = np.load('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_nval_images.npy')\n",
    "labels = np.load('/Thesis/MicroExpSTCNN/Eval_dataset_CASME/intermediate_microexpfusenet_eval_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8cf07-0546-4f02-96ba-c908f25d23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion Matrix using pretrained weights\n",
    "predictions = model.predict([eimg, nimg])\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "validation_labels = np.argmax(labels, axis=1)\n",
    "cfm = confusion_matrix(validation_labels, predictions_labels)\n",
    "print (cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa213db8-4724-4372-b322-65eda487f671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017f51a-a944-4342-b201-2edc362a3159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010fda6-7556-46a1-831f-841feae46bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db42f2-4a38-487b-8929-aabb3626cf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc0d284-e90e-4339-b5c7-d5d156dd32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_train_image, le_test_image, re_train_image, re_test_image, m_train_image, m_test_image, f_train_image, f_test_image, y_train, y_test =  train_test_split(left_eye_training_set, right_eye_training_set, mouth_training_set, total_face_training_set, left_eye_traininglabels, test_size=0.2, shuffle=False)\n",
    "\n",
    "le_train_label = y_train\n",
    "le_test_label = y_test\n",
    "\n",
    "re_train_label = y_train\n",
    "re_test_label = y_test\n",
    "\n",
    "m_train_label = y_train\n",
    "m_test_label = y_test\n",
    "\n",
    "f_train_label = y_train\n",
    "f_test_label = y_test\n",
    "\n",
    "# Convert Into Tensors\n",
    "le_train_data = tf.data.Dataset.from_tensor_slices((le_train_image, le_train_label)).batch(8, drop_remainder=True)\n",
    "le_test_data = tf.data.Dataset.from_tensor_slices((le_test_image, le_test_label)).batch(8, drop_remainder=True)\n",
    "\n",
    "re_train_data = tf.data.Dataset.from_tensor_slices((re_train_image, re_train_label)).batch(8, drop_remainder=True)\n",
    "re_test_data = tf.data.Dataset.from_tensor_slices((re_test_image, re_test_label)).batch(8, drop_remainder=True)\n",
    "\n",
    "m_train_data = tf.data.Dataset.from_tensor_slices((m_train_image, m_train_label)).batch(8, drop_remainder=True)\n",
    "m_test_data = tf.data.Dataset.from_tensor_slices((m_test_image, m_test_label)).batch(8, drop_remainder=True)\n",
    "\n",
    "f_train_data = tf.data.Dataset.from_tensor_slices((f_train_image, f_train_label)).batch(8, drop_remainder=True)\n",
    "f_test_data = tf.data.Dataset.from_tensor_slices((f_test_image, f_test_label)).batch(8, drop_remainder=True)\n",
    "\n",
    "# Use the below dataset for model.fit\n",
    "# train_All_dataset = tf.data.Dataset.from_tensor_slices(({\"NET_A_InputLayer\": x_train_A, \"NET_B_InputLayer\": x_train_B}, y_train_A)).batch(8, drop_remainder=True)\n",
    "# test_All_dataset = tf.data.Dataset.from_tensor_slices(({\"NET_A_InputLayer\": x_test_A, \"NET_B_InputLayer\": x_test_B}, y_test_A)).batch(8, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1aa7722-ffbc-49af-ab28-2cdd28a62472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n",
      "Step: 0 Loss: 1.2566031217575073 Accuracy: 0.125\n",
      "Step: 4 Loss: 19.362140655517578 Accuracy: 0.59375\n",
      "Step: 8 Loss: 0.0 Accuracy: 0.875\n",
      "Epoch :  2\n",
      "Step: 0 Loss: 160.75033569335938 Accuracy: 0.75\n",
      "Step: 4 Loss: 25.746721267700195 Accuracy: 0.15625\n",
      "Step: 8 Loss: 0.005032298155128956 Accuracy: 0.25\n",
      "Epoch :  3\n",
      "Step: 0 Loss: 42.51869201660156 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.008433401584625244 Accuracy: 0.40625\n",
      "Step: 8 Loss: 0.10772304981946945 Accuracy: 0.3125\n",
      "Epoch :  4\n",
      "Step: 0 Loss: 13.83750057220459 Accuracy: 0.65625\n",
      "Step: 4 Loss: 3.5293445587158203 Accuracy: 0.1875\n",
      "Step: 8 Loss: 0.13494634628295898 Accuracy: 0.625\n",
      "Epoch :  5\n",
      "Step: 0 Loss: 3.0352394580841064 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.6509714126586914 Accuracy: 0.3125\n",
      "Step: 8 Loss: 0.09652253985404968 Accuracy: 0.5625\n",
      "Epoch :  6\n",
      "Step: 0 Loss: 3.8710169792175293 Accuracy: 0.75\n",
      "Step: 4 Loss: 1.4007847309112549 Accuracy: 0.125\n",
      "Step: 8 Loss: 0.10750007629394531 Accuracy: 0.8125\n",
      "Epoch :  7\n",
      "Step: 0 Loss: 1.1944377422332764 Accuracy: 0.6875\n",
      "Step: 4 Loss: 0.2942751944065094 Accuracy: 0.75\n",
      "Step: 8 Loss: 0.009018125012516975 Accuracy: 0.84375\n",
      "Epoch :  8\n",
      "Step: 0 Loss: 5.465737342834473 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.01699347235262394 Accuracy: 0.65625\n",
      "Step: 8 Loss: 1.5723011493682861 Accuracy: 0.34375\n",
      "Epoch :  9\n",
      "Step: 0 Loss: 3.7543482780456543 Accuracy: 0.71875\n",
      "Step: 4 Loss: 0.48656442761421204 Accuracy: 0.3125\n",
      "Step: 8 Loss: 0.25240543484687805 Accuracy: 0.90625\n",
      "Epoch :  10\n",
      "Step: 0 Loss: 1.4668874740600586 Accuracy: 0.75\n",
      "Step: 4 Loss: 1.5647759437561035 Accuracy: 0.09375\n",
      "Step: 8 Loss: 0.4448046088218689 Accuracy: 0.25\n",
      "Epoch :  11\n",
      "Step: 0 Loss: 3.1433520317077637 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.1634269505739212 Accuracy: 0.40625\n",
      "Step: 8 Loss: 0.25613415241241455 Accuracy: 1.0\n",
      "Epoch :  12\n",
      "Step: 0 Loss: 1.2611629962921143 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.47827064990997314 Accuracy: 0.40625\n",
      "Step: 8 Loss: 0.4526454508304596 Accuracy: 1.0\n",
      "Epoch :  13\n",
      "Step: 0 Loss: 1.1424025297164917 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.35825464129447937 Accuracy: 0.40625\n",
      "Step: 8 Loss: 0.2585085332393646 Accuracy: 1.0\n",
      "Epoch :  14\n",
      "Step: 0 Loss: 1.4741952419281006 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.2782400846481323 Accuracy: 0.40625\n",
      "Step: 8 Loss: 0.23137295246124268 Accuracy: 1.0\n",
      "Epoch :  15\n",
      "Step: 0 Loss: 1.3487958908081055 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.3175657093524933 Accuracy: 0.40625\n",
      "Step: 8 Loss: 0.24798119068145752 Accuracy: 1.0\n",
      "Epoch :  16\n",
      "Step: 0 Loss: 1.276671290397644 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.308003693819046 Accuracy: 0.4375\n",
      "Step: 8 Loss: 0.21325260400772095 Accuracy: 1.0\n",
      "Epoch :  17\n",
      "Step: 0 Loss: 1.3271255493164062 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.2820112109184265 Accuracy: 0.46875\n",
      "Step: 8 Loss: 0.19566182792186737 Accuracy: 0.96875\n",
      "Epoch :  18\n",
      "Step: 0 Loss: 1.2832227945327759 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.2730489671230316 Accuracy: 0.5\n",
      "Step: 8 Loss: 0.1845347136259079 Accuracy: 0.96875\n",
      "Epoch :  19\n",
      "Step: 0 Loss: 1.262932300567627 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.24634529650211334 Accuracy: 0.53125\n",
      "Step: 8 Loss: 0.17145177721977234 Accuracy: 0.96875\n",
      "Epoch :  20\n",
      "Step: 0 Loss: 1.2490525245666504 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.21719500422477722 Accuracy: 0.59375\n",
      "Step: 8 Loss: 0.16947099566459656 Accuracy: 0.90625\n",
      "Epoch :  21\n",
      "Step: 0 Loss: 1.2266602516174316 Accuracy: 0.75\n",
      "Step: 4 Loss: 0.18512359261512756 Accuracy: 0.71875\n",
      "Step: 8 Loss: 0.1731669008731842 Accuracy: 0.84375\n",
      "Epoch :  22\n",
      "Step: 0 Loss: 1.2193177938461304 Accuracy: 0.6875\n",
      "Step: 4 Loss: 0.15288391709327698 Accuracy: 0.71875\n",
      "Step: 8 Loss: 0.18544593453407288 Accuracy: 0.875\n",
      "Epoch :  23\n",
      "Step: 0 Loss: 1.2022454738616943 Accuracy: 0.6875\n",
      "Step: 4 Loss: 0.12136916816234589 Accuracy: 0.71875\n",
      "Step: 8 Loss: 0.19922062754631042 Accuracy: 0.875\n",
      "Epoch :  24\n",
      "Step: 0 Loss: 1.1717109680175781 Accuracy: 0.6875\n",
      "Step: 4 Loss: 0.09212534129619598 Accuracy: 0.75\n",
      "Step: 8 Loss: 0.21199312806129456 Accuracy: 0.90625\n",
      "Epoch :  25\n",
      "Step: 0 Loss: 1.079827070236206 Accuracy: 0.71875\n",
      "Step: 4 Loss: 0.06542465090751648 Accuracy: 0.78125\n",
      "Step: 8 Loss: 0.20721036195755005 Accuracy: 0.875\n",
      "Epoch :  26\n",
      "Step: 0 Loss: 0.9238110780715942 Accuracy: 0.8125\n",
      "Step: 4 Loss: 0.0429520308971405 Accuracy: 0.8125\n",
      "Step: 8 Loss: 0.18818828463554382 Accuracy: 0.875\n",
      "Epoch :  27\n",
      "Step: 0 Loss: 0.7232893705368042 Accuracy: 0.875\n",
      "Step: 4 Loss: 0.02286805957555771 Accuracy: 0.875\n",
      "Step: 8 Loss: 0.17752738296985626 Accuracy: 0.90625\n",
      "Epoch :  28\n",
      "Step: 0 Loss: 0.5870490670204163 Accuracy: 0.9375\n",
      "Step: 4 Loss: 0.01354886218905449 Accuracy: 0.9375\n",
      "Step: 8 Loss: 0.17146846652030945 Accuracy: 1.0\n",
      "Epoch :  29\n",
      "Step: 0 Loss: 0.16785812377929688 Accuracy: 0.96875\n",
      "Step: 4 Loss: 0.00392910884693265 Accuracy: 0.9375\n",
      "Step: 8 Loss: 0.0817745178937912 Accuracy: 1.0\n",
      "Epoch :  30\n",
      "Step: 0 Loss: 0.12366000562906265 Accuracy: 0.96875\n",
      "Step: 4 Loss: 0.006722630467265844 Accuracy: 0.96875\n",
      "Step: 8 Loss: 0.12770047783851624 Accuracy: 1.0\n",
      "Epoch :  31\n",
      "Step: 0 Loss: 0.13077962398529053 Accuracy: 0.96875\n",
      "Step: 4 Loss: 0.0020725387148559093 Accuracy: 0.96875\n",
      "Step: 8 Loss: 0.05933906510472298 Accuracy: 1.0\n",
      "Epoch :  32\n",
      "Step: 0 Loss: 0.021509820595383644 Accuracy: 1.0\n",
      "Step: 4 Loss: 0.0031918559689074755 Accuracy: 0.96875\n",
      "Step: 8 Loss: 0.07210874557495117 Accuracy: 1.0\n",
      "Epoch :  33\n",
      "Step: 0 Loss: 0.055222224444150925 Accuracy: 1.0\n",
      "Step: 4 Loss: 0.0006706587155349553 Accuracy: 0.96875\n",
      "Step: 8 Loss: 0.06872288882732391 Accuracy: 1.0\n",
      "Epoch :  34\n",
      "Step: 0 Loss: 0.0003492565010674298 Accuracy: 1.0\n",
      "Step: 4 Loss: 0.00038612884236499667 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.022539393976330757 Accuracy: 1.0\n",
      "Epoch :  35\n",
      "Step: 0 Loss: 0.00031435853452421725 Accuracy: 1.0\n",
      "Step: 4 Loss: 0.00013087739353068173 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.018295522779226303 Accuracy: 1.0\n",
      "Epoch :  36\n",
      "Step: 0 Loss: 0.00030963282915763557 Accuracy: 1.0\n",
      "Step: 4 Loss: 5.9866997617064044e-05 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.010782240889966488 Accuracy: 1.0\n",
      "Epoch :  37\n",
      "Step: 0 Loss: 0.0003121892223134637 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.1916642910800874e-05 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.007288866676390171 Accuracy: 1.0\n",
      "Epoch :  38\n",
      "Step: 0 Loss: 0.0002859442320186645 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.190393570344895e-05 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.005915858317166567 Accuracy: 1.0\n",
      "Epoch :  39\n",
      "Step: 0 Loss: 0.0002534445084165782 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.6137539205374196e-05 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.004790827166289091 Accuracy: 1.0\n",
      "Epoch :  40\n",
      "Step: 0 Loss: 0.0002278845349792391 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.2188913387944922e-05 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.003892481094226241 Accuracy: 1.0\n",
      "Epoch :  41\n",
      "Step: 0 Loss: 0.0002068369503831491 Accuracy: 1.0\n",
      "Step: 4 Loss: 9.566399967297912e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0032686088234186172 Accuracy: 1.0\n",
      "Epoch :  42\n",
      "Step: 0 Loss: 0.00018854447989724576 Accuracy: 1.0\n",
      "Step: 4 Loss: 7.73360807215795e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0028151851147413254 Accuracy: 1.0\n",
      "Epoch :  43\n",
      "Step: 0 Loss: 0.00017291793483309448 Accuracy: 1.0\n",
      "Step: 4 Loss: 6.392533578036819e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.002455170266330242 Accuracy: 1.0\n",
      "Epoch :  44\n",
      "Step: 0 Loss: 0.0001597192167537287 Accuracy: 1.0\n",
      "Step: 4 Loss: 5.40907558388426e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.002159431343898177 Accuracy: 1.0\n",
      "Epoch :  45\n",
      "Step: 0 Loss: 0.00014847173588350415 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.604425612342311e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0019151881569996476 Accuracy: 1.0\n",
      "Epoch :  46\n",
      "Step: 0 Loss: 0.0001386691292282194 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.008387804788072e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0017126398161053658 Accuracy: 1.0\n",
      "Epoch :  47\n",
      "Step: 0 Loss: 0.00013005819346290082 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.4421495911374222e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0015425404999405146 Accuracy: 1.0\n",
      "Epoch :  48\n",
      "Step: 0 Loss: 0.00012235590838827193 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.069624654017389e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0013979909708723426 Accuracy: 1.0\n",
      "Epoch :  49\n",
      "Step: 0 Loss: 0.00011550274211913347 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.726901129790349e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0012739102821797132 Accuracy: 1.0\n",
      "Epoch :  50\n",
      "Step: 0 Loss: 0.00010934971942333505 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.4586825020378456e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0011662215692922473 Accuracy: 1.0\n",
      "Epoch :  51\n",
      "Step: 0 Loss: 0.00010370317613705993 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.1755622583441436e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0010723164305090904 Accuracy: 1.0\n",
      "Epoch :  52\n",
      "Step: 0 Loss: 9.86376398941502e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.996749460886349e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0009898507269099355 Accuracy: 1.0\n",
      "Epoch :  53\n",
      "Step: 0 Loss: 9.394451626576483e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.8179366634285543e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0009169252589344978 Accuracy: 1.0\n",
      "Epoch :  54\n",
      "Step: 0 Loss: 8.968343172455207e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.6838270084917895e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0008520105620846152 Accuracy: 1.0\n",
      "Epoch :  55\n",
      "Step: 0 Loss: 8.576500113122165e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.5497171261813492e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0007939786883071065 Accuracy: 1.0\n",
      "Epoch :  56\n",
      "Step: 0 Loss: 8.209982479456812e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.4603106137656141e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0007419086759909987 Accuracy: 1.0\n",
      "Epoch :  57\n",
      "Step: 0 Loss: 7.871771231293678e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.3112996839481639e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0006949689122848213 Accuracy: 1.0\n",
      "Epoch :  58\n",
      "Step: 0 Loss: 7.558887591585517e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.236794105352601e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0006524311029352248 Accuracy: 1.0\n",
      "Epoch :  59\n",
      "Step: 0 Loss: 7.269840716617182e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.1324862043693429e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0006138497265055776 Accuracy: 1.0\n",
      "Epoch :  60\n",
      "Step: 0 Loss: 6.994201248744503e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.0430796919536078e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0005787044647149742 Accuracy: 1.0\n",
      "Epoch :  61\n",
      "Step: 0 Loss: 6.739421223755926e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 1.0132773695659125e-06 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0005465792492032051 Accuracy: 1.0\n",
      "Epoch :  62\n",
      "Step: 0 Loss: 6.504008342744783e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 9.536729521641973e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0005171767552383244 Accuracy: 1.0\n",
      "Epoch :  63\n",
      "Step: 0 Loss: 6.27902481937781e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 8.642662692182057e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.000490110251121223 Accuracy: 1.0\n",
      "Epoch :  64\n",
      "Step: 0 Loss: 6.0659593145828694e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 8.344639468305104e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00046517158625647426 Accuracy: 1.0\n",
      "Epoch :  65\n",
      "Step: 0 Loss: 5.867793515790254e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 8.046617381296528e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00044216756941750646 Accuracy: 1.0\n",
      "Epoch :  66\n",
      "Step: 0 Loss: 5.680056710843928e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 7.599584250783664e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00042087503243237734 Accuracy: 1.0\n",
      "Epoch :  67\n",
      "Step: 0 Loss: 5.499769395100884e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 7.152550551836612e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0004010559059679508 Accuracy: 1.0\n",
      "Epoch :  68\n",
      "Step: 0 Loss: 5.328420957084745e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 7.003538939898135e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00038265070179477334 Accuracy: 1.0\n",
      "Epoch :  69\n",
      "Step: 0 Loss: 5.170482836547308e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 6.705516284455371e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00036549585638567805 Accuracy: 1.0\n",
      "Epoch :  70\n",
      "Step: 0 Loss: 5.0170139729743823e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 6.407493629012606e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00034951698035001755 Accuracy: 1.0\n",
      "Epoch :  71\n",
      "Step: 0 Loss: 4.8724847147241235e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 5.811447749692888e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00033458013786002994 Accuracy: 1.0\n",
      "Epoch :  72\n",
      "Step: 0 Loss: 4.7368946979986504e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 5.6624367061886e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00032055130577646196 Accuracy: 1.0\n",
      "Epoch :  73\n",
      "Step: 0 Loss: 4.604284549714066e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 5.215402438807359e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0003074157575611025 Accuracy: 1.0\n",
      "Epoch :  74\n",
      "Step: 0 Loss: 4.4761443859897554e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.917379783364595e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00029508420266211033 Accuracy: 1.0\n",
      "Epoch :  75\n",
      "Step: 0 Loss: 4.355453347670846e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.917379783364595e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002835119084920734 Accuracy: 1.0\n",
      "Epoch :  76\n",
      "Step: 0 Loss: 4.23923265771009e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.917379783364595e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002725649392232299 Accuracy: 1.0\n",
      "Epoch :  77\n",
      "Step: 0 Loss: 4.131951573072001e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.470345515983354e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002622731262817979 Accuracy: 1.0\n",
      "Epoch :  78\n",
      "Step: 0 Loss: 4.026160604553297e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.470345515983354e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002525768941268325 Accuracy: 1.0\n",
      "Epoch :  79\n",
      "Step: 0 Loss: 3.923349504475482e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.470345515983354e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002434464986436069 Accuracy: 1.0\n",
      "Epoch :  80\n",
      "Step: 0 Loss: 3.827988257398829e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.023311248602113e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002347628033021465 Accuracy: 1.0\n",
      "Epoch :  81\n",
      "Step: 0 Loss: 3.738587111001834e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 4.023311248602113e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00022652585175819695 Accuracy: 1.0\n",
      "Epoch :  82\n",
      "Step: 0 Loss: 3.646205004770309e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.874299636663636e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00021876540267840028 Accuracy: 1.0\n",
      "Epoch :  83\n",
      "Step: 0 Loss: 3.556803130777553e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.874299636663636e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0002114070812240243 Accuracy: 1.0\n",
      "Epoch :  84\n",
      "Step: 0 Loss: 3.476341953501105e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.725288593159348e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00020436143677216023 Accuracy: 1.0\n",
      "Epoch :  85\n",
      "Step: 0 Loss: 3.3958800486288965e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.5762769812208717e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.000197703018784523 Accuracy: 1.0\n",
      "Epoch :  86\n",
      "Step: 0 Loss: 3.319888492114842e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.5762769812208717e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00019134242029394954 Accuracy: 1.0\n",
      "Epoch :  87\n",
      "Step: 0 Loss: 3.242406455683522e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.5762769812208717e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00018529458611737937 Accuracy: 1.0\n",
      "Epoch :  88\n",
      "Step: 0 Loss: 3.1753548682900146e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.427265369282395e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00017952972848434 Accuracy: 1.0\n",
      "Epoch :  89\n",
      "Step: 0 Loss: 3.1038332963362336e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.278254041561013e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00017401803052052855 Accuracy: 1.0\n",
      "Epoch :  90\n",
      "Step: 0 Loss: 3.0382714612642303e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 3.1292427138396306e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00016875953588169068 Accuracy: 1.0\n",
      "Epoch :  91\n",
      "Step: 0 Loss: 2.974199378513731e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.980231101901154e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00016373934340663254 Accuracy: 1.0\n",
      "Epoch :  92\n",
      "Step: 0 Loss: 2.9131077099009417e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.682207878024201e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00015892765077296644 Accuracy: 1.0\n",
      "Epoch :  93\n",
      "Step: 0 Loss: 2.852015859389212e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.682207878024201e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00015432450163643807 Accuracy: 1.0\n",
      "Epoch :  94\n",
      "Step: 0 Loss: 2.793903877318371e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.682207878024201e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00014992986689321697 Accuracy: 1.0\n",
      "Epoch :  95\n",
      "Step: 0 Loss: 2.7357920771464705e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.682207878024201e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00014569907216355205 Accuracy: 1.0\n",
      "Epoch :  96\n",
      "Step: 0 Loss: 2.683640195755288e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.5331965503028187e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00014164700405672193 Accuracy: 1.0\n",
      "Epoch :  97\n",
      "Step: 0 Loss: 2.6299985620426014e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.5331965503028187e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00013778856373392045 Accuracy: 1.0\n",
      "Epoch :  98\n",
      "Step: 0 Loss: 2.5748664484126493e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.5331965503028187e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00013406420475803316 Accuracy: 1.0\n",
      "Epoch :  99\n",
      "Step: 0 Loss: 2.5256947992602363e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.5331965503028187e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.00013047388347331434 Accuracy: 1.0\n",
      "Epoch :  100\n",
      "Step: 0 Loss: 2.4795028366497718e-05 Accuracy: 1.0\n",
      "Step: 4 Loss: 2.5331965503028187e-07 Accuracy: 1.0\n",
      "Step: 8 Loss: 0.0001270027132704854 Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=1e-3)  # tune this\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch : \", epoch+1)\n",
    "    for step, ((image_batch1, label_batch1),(image_batch2, label_batch2),(image_batch3, label_batch3),(image_batch4, label_batch4)) in enumerate(zip(le_train_data,re_train_data,m_train_data,f_train_data)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model([image_batch1, image_batch2, image_batch3, image_batch4])\n",
    "            # loss format is generally: first argument targets, second argument outputs\n",
    "            loss = loss_fn(label_batch1, logits)\n",
    "\n",
    "        variables = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        train_acc_metric(label_batch1, logits)\n",
    "        if not step % 4:\n",
    "            print(\"Step: {} Loss: {} Accuracy: {}\".format(step, loss, train_acc_metric.result()))\n",
    "            train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2156cada-4a52-47b9-9e34-aecb541ae812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.1666666716337204\n"
     ]
    }
   ],
   "source": [
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "for  step, ((image_batch1, label_batch1),(image_batch2, label_batch2),(image_batch3, label_batch3),(image_batch4, label_batch4)) in enumerate(zip(le_test_data, re_test_data, m_test_data, f_test_data)):\n",
    "    test_acc_metric(label_batch1, model([image_batch1, image_batch2, image_batch3, image_batch4]))\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b8b4a-6242-4d61-91c5-bcdcb2db65b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
