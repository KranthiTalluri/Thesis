{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5258058e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3488caa-5a30-4876-b352-5ae8a93afcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pylab\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import skimage.io as imageio\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "#from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate, Input, concatenate, add, multiply, maximum, LSTM, Reshape\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#K.set_image_dim_ordering('th')\n",
    "#K.set_image_data_format('channels_first')\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ca99e",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4776d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afb8ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f82c1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff91c2d-6d23-4632-862b-3ea95e1b8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_image_dim_ordering('th')\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c48a2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Excel to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Thesis/Datasets/CASME2/CASME2-coding-20190701.xlsx') #index_col=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cfc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed366712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subject'] = df['Subject'].astype(str)\n",
    "df['Sub_FileName'] = df[['Subject', 'Filename']].apply(lambda x: '_'.join(x), axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985482f-15e7-4896-b135-0ca450f6ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df[df['Estimated Emotion'] == 'happiness']['Sub_FileName']#[['Subject','Filename']]\n",
    "print('Positive :', positive.count())\n",
    "\n",
    "negative = df[(df['Estimated Emotion'] == 'disgust') | (df['Estimated Emotion'] == 'repression') | (df['Estimated Emotion'] == 'fear') | (df['Estimated Emotion'] == 'sadness')]['Sub_FileName']\n",
    "print('Negative :',negative.count())\n",
    "\n",
    "surprise = df[df['Estimated Emotion'] == 'surprise']['Sub_FileName']\n",
    "print('Surprise :',surprise.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189a2a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15212b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectPath = '/Thesis/Datasets/CASME2/CASME2_Cropped_updated/Cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc86eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows, image_columns, frames_Count = 64, 64, 48\n",
    "training_casme_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a03793a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SAMM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5715265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_count = 0\n",
    "for lab in [positive, negative, surprise]: \n",
    "    subDirectory = lab#.tolist() \n",
    "    count = 0\n",
    "    for sub in tqdm(subDirectory):\n",
    "        sub = str(sub).split('_')\n",
    "        labelpath = '/Thesis/Datasets/CASME2/CASME2_RAW_selected/'+'sub'+ sub[0].zfill(2) +'/'\n",
    "        directorylisting = os.listdir(labelpath)\n",
    "        for video in directorylisting:\n",
    "            if video == str(sub[1]+'_'+sub[2]):\n",
    "                frames = []\n",
    "                total_face_frames = []\n",
    "                videopath = labelpath + video\n",
    "                framelisting = os.listdir(videopath)\n",
    "                if len(framelisting) > frames_Count:\n",
    "                    framerange = [x  for x in range(frames_Count)]\n",
    "                    count = count + 1\n",
    "                    for frame in framerange:\n",
    "                        imagepath = videopath + \"/\" + framelisting[frame]\n",
    "                        image = cv2.imread(imagepath)\n",
    "                        imageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
    "                        grayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
    "                        frames.append(grayimage)\n",
    "                    frames = np.asarray(frames)\n",
    "                    #videoarray = np.rollaxis(np.rollaxis(frames, 2, 0), 2, 0)\n",
    "                    training_casme_list.append(frames)\n",
    "                # break\n",
    "    \n",
    "    print(count)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0526a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_casme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d0efc-5a23-4747-b1a2-4a11afc458fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_casme_list[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee108b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "290+744"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adb646",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379871d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_casme_list = np.asarray(training_casme_list)\n",
    "training_casme_samples = len(training_casme_list)\n",
    "\n",
    "training_casme_labels = np.zeros((training_casme_samples, ), dtype = int)\n",
    "\n",
    "training_casme_labels[0:27] = 0\n",
    "training_casme_labels[27:103] = 1\n",
    "training_casme_labels[103:124] = 2\n",
    "\n",
    "training_casme_labels = np_utils.to_categorical(training_casme_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4745f-6e6d-4000-b378-abfa73689d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_casme_data = [training_casme_list, training_casme_labels]\n",
    "(training_frames_casme, traininglabels_casme) = (training_casme_data[0], training_casme_data[1])\n",
    "training_casme_set = np.zeros((training_casme_samples, 1, image_rows, image_columns, frames_Count))\n",
    "for h in range(training_casme_samples):\n",
    "    training_casme_set[h][0][:][:][:] = training_frames_casme[h,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbcd11f-857c-411e-8ef2-4f42e4c84ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_casme_set = training_casme_set.astype('float32')\n",
    "training_casme_set -= np.mean(training_casme_set)\n",
    "training_casme_set /= np.max(training_casme_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_casme_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed54da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Nump Arrays to save time\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Sample_datasets/microexp_casme_images.npy', training_casme_set)\n",
    "np.save('/Thesis/Multi_Scale_MicroExp/Sample_datasets/microexp_casme_labels.npy', training_casme_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e6e89",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loading Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e4dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_casme_set = None\n",
    "training_casme_labels = None\n",
    "training_casme_set  = np.load('/Thesis/Multi_Scale_MicroExp/Sample_datasets/microexp_casme_images.npy')\n",
    "training_casme_labels = np.load('/Thesis/Multi_Scale_MicroExp/Sample_datasets/microexp_casme_labels.npy')\n",
    "\n",
    "training_casme_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee2992-0b6b-4542-bf33-32e6ab8d9c1c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e177ced-d4eb-4004-8fbf-aa1609d1fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution3D(32, (3, 3, 15), input_shape=(1, image_rows, image_columns, frames_Count), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd97a8-872f-4d11-98d4-62d810658b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained weights\n",
    "\n",
    "#model.load_weights('/Thesis/MicroExpSTCNN/Training_dataset/weights_microexpstcnn/weights-improvement-53-0.88.hdf5')\n",
    "\n",
    "#model.load_weights('/Thesis/MicroExpSTCNN/CASME_SQUARE/weights-improvement-53-0.88.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e86627-9d4b-4460-a0df-856c6dfa148b",
   "metadata": {},
   "source": [
    "#### Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bf393-b6a8-47ac-9298-e42b9155e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=10, decay_rate=0.90, staircase=True)\n",
    "\n",
    "model.compile( loss=\"categorical_crossentropy\", optimizer= tf.keras.optimizers.Adam(learning_rate=lr_schedule), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db381c68-91cc-4952-ab00-b3bfc56c9e2a",
   "metadata": {},
   "source": [
    "#### Creating checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22e16a-8566-41f6-acc1-de5461aa377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"/Thesis/Multi_Scale_MicroExp/Sample_datasets/weights_microexp/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=25)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ebf60-8672-496d-8826-d2aeffb3613f",
   "metadata": {},
   "source": [
    "#### Spliting the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f58faf-02e2-4c4e-a119-0237d4a01c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, train_labels, validation_labels =  train_test_split(training_casme_set, training_casme_labels, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9377792-a982-44da-b41e-205dc1c1728e",
   "metadata": {},
   "source": [
    "#### Save validation set in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8f595-6f21-4706-8d48-ac2ef4dd8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset/microexpstcnn_val_images.npy', validation_images)\n",
    "np.save('/Thesis/MicroExpSTCNN/Training_dataset/microexpstcnn_val_labels.npy', validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01c86c-82f3-46e8-8691-c8b76858d7a4",
   "metadata": {},
   "source": [
    "#### Load validation set from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8e320-8ec7-4748-ab3c-d283cb654d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = np.load('/Thesis/MicroExpSTCNN/Training_dataset/microexpstcnn_val_images.npy')\n",
    "validation_labels = np.load('/Thesis/MicroExpSTCNN/Training_dataset/microexpstcnn_val_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b06b58-41b5-47bb-89d5-33ce2d8bcb52",
   "metadata": {},
   "source": [
    "#### Pre-Trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac83ae-6a53-419e-b8b0-593793ccc2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_images = np.load('/Thesis/MicroExpSTCNN/CASME_SQUARE/microexpstcnn_val_images.npy')\n",
    "#validation_labels = np.load('/Thesis/MicroExpSTCNN/CASME_SQUARE/microexpstcnn_val_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eeb2e1-108d-4fca-b6cc-9ffced1640ba",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd79389-9297-4c36-ab36-be7aac19f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_images, train_labels, validation_data = (validation_images, validation_labels), callbacks=callbacks_list, batch_size = 8, epochs = 100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8e6d1-f5bc-499e-a418-ed1050cd422e",
   "metadata": {},
   "source": [
    "#### Finding Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe846821-c995-4317-8ada-e07ae2e2cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_images)\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "validation_labels = np.argmax(validation_labels, axis=1)\n",
    "cfm = confusion_matrix(validation_labels, predictions_labels)\n",
    "print (cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f4b3c-dfd8-47a4-b791-c94c5cdb4643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
